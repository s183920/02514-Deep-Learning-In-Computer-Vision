{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work3/s183920/02514-DLCI/DLCI-venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/work3/s183920/02514-DLCI/DLCI-venv/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import json\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TacoDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Class to store the food data\n",
    "    \"\"\"\n",
    "    root_dir = '/dtu/datasets1/02514/data_wastedetection/'\n",
    "    anns_file_path = root_dir + '/' + 'annotations.json'\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Read annotations\n",
    "        with open(self.anns_file_path, 'r') as f:\n",
    "            self.dataset = json.loads(f.read())\n",
    "        \n",
    "        self.categories = self.dataset['categories']\n",
    "        self.anns = self.dataset['annotations']\n",
    "        self.imgs = self.dataset['images']\n",
    "        \n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_meta = self.imgs[idx]\n",
    "        img_ann = self.anns[idx]\n",
    "        # img = np.load(self.root_dir + img_meta['file_name'])\n",
    "        img = PIL.Image.open(self.root_dir + img_meta['file_name'])\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        return img, img_meta, img_ann\n",
    "        # return img_meta\n",
    "\n",
    "def show_img(img, ax = None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    return ax\n",
    "\n",
    "dataset = TacoDataset()\n",
    "img, img_meta, img_ann = dataset.__getitem__(0)\n",
    "\n",
    "show_img(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_poly_to_mask(segmentations, height, width):\n",
    "    masks = []\n",
    "    for polygons in segmentations:\n",
    "        rles = coco_mask.frPyObjects(polygons, height, width)\n",
    "        mask = coco_mask.decode(rles)\n",
    "        if len(mask.shape) < 3:\n",
    "            mask = mask[..., None]\n",
    "        mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
    "        mask = mask.any(dim=2)\n",
    "        masks.append(mask)\n",
    "    if masks:\n",
    "        masks = torch.stack(masks, dim=0)\n",
    "    else:\n",
    "        masks = torch.zeros((0, height, width), dtype=torch.uint8)\n",
    "    return masks\n",
    "\n",
    "class EncordMaskRCNNDataset(torchvision.datasets.CocoDetection):\n",
    "   def __init__(self, img_folder, ann_file, transforms=None):\n",
    "       super().__init__(img_folder, ann_file)\n",
    "       self._transforms = transforms\n",
    " \n",
    "   def __getitem__(self, idx):\n",
    "       img, target = super().__getitem__(idx)\n",
    "       img_metadata = self.coco.loadImgs(self.ids[idx])\n",
    " \n",
    "       image_id = self.ids[idx]\n",
    "       img_width, img_height = img.size\n",
    " \n",
    "       boxes, labels, area, iscrowd = [], [], [], []\n",
    "       for target_item in target:\n",
    "           boxes.append(\n",
    "               [\n",
    "                   target_item[\"bbox\"][0],\n",
    "                   target_item[\"bbox\"][1],\n",
    "                   target_item[\"bbox\"][0] + target_item[\"bbox\"][2],\n",
    "                   target_item[\"bbox\"][1] + target_item[\"bbox\"][3],\n",
    "               ]\n",
    "           )\n",
    " \n",
    "           labels.append(target_item[\"category_id\"])\n",
    "           area.append(target_item[\"bbox\"][2] * target_item[\"bbox\"][3])\n",
    "           iscrowd.append(target_item[\"iscrowd\"])\n",
    " \n",
    "       segmentations = [obj[\"segmentation\"] for obj in target]\n",
    "       masks = convert_coco_poly_to_mask(segmentations, img_height, img_width)\n",
    " \n",
    "       processed_target = {}\n",
    "       processed_target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "       processed_target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "       processed_target[\"masks\"] = masks\n",
    "       processed_target[\"image_id\"] = torch.tensor([image_id])\n",
    "       processed_target[\"area\"] = torch.tensor(area)\n",
    "       processed_target[\"iscrowd\"] = torch.as_tensor(iscrowd, dtype=torch.int64)\n",
    " \n",
    "       if self._transforms is not None:\n",
    "           img, processed_target = self._transforms(img, processed_target)\n",
    " \n",
    "       return img, processed_target, img_metadata\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLCI-venv",
   "language": "python",
   "name": "dlci-venv"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
