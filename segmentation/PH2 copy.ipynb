{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b09268-6d97-4297-9907-006ec930abd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.chdir('02514-Deep-Learning-In-Computer-Vision/')\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "\n",
    "# pip install torchsummary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from time import time\n",
    "from dataloader import Lesion_Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on \", device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93ef46d-098f-4c62-baac-0d4685e4b99c",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c52f7e76-918f-4011-b51e-f87d32c2324c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 128 training images\n",
      "Loaded 40 test images\n",
      "Loaded 32 validation images\n"
     ]
    }
   ],
   "source": [
    "size = 128\n",
    "batch_size = 6\n",
    "\n",
    "dataset = Lesion_Data(train_transform_size=size, test_transform_size=size)\n",
    "trainset, testset, validationset = dataset.get_datasets()\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "validation_loader = DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "print('Loaded %d training images' % len(trainset))\n",
    "print('Loaded %d test images' % len(testset))\n",
    "print('Loaded %d validation images' % len(validationset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d965a0ad-d13f-4f10-9fb6-f1d388e6974d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [18, 6]\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 6, i+1)\n",
    "    plt.imshow(np.swapaxes(np.swapaxes(images[i], 0, 2), 0, 1))\n",
    "\n",
    "    plt.subplot(2, 6, i+7)\n",
    "    plt.imshow(labels[i].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1faa24dd-619e-446b-97e8-7c5b88b43e05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf53302-88a4-45e5-a787-cd4f7a47b042",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7f519bb552d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2b29a1-d7e0-4460-94ee-34106b973aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, opt, loss_fn, epochs, train_loader, test_loader):\n",
    "    X_test, Y_test = next(iter(test_loader))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        model.train()  # train mode\n",
    "        for X_batch, Y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "\n",
    "            # set parameter gradients to zero\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            # loss = loss_fn(Y_batch, torch.argmax(Y_pred, dim = 1))  # forward-pass\n",
    "            loss = loss_fn(Y_batch, Y_pred)  # forward-pass\n",
    "            loss.backward()  # backward-pass\n",
    "            opt.step()  # update weights\n",
    "\n",
    "            # calculate metrics to show the user\n",
    "            avg_loss += loss / len(train_loader)\n",
    "        toc = time()\n",
    "        print(' - loss: %f' % avg_loss)\n",
    "\n",
    "        # show intermediate results\n",
    "        model.eval()  # testing mode\n",
    "        Y_hat = F.sigmoid(model(X_test.to(device))).detach().cpu()\n",
    "        clear_output(wait=True)\n",
    "        for k in range(4):\n",
    "            plt.subplot(2, 6, k+1)\n",
    "            plt.imshow(np.rollaxis(X_test[k].numpy(), 0, 3), cmap='gray')\n",
    "            plt.title('Real')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(2, 6, k+7)\n",
    "            plt.imshow(Y_hat[k, 0], cmap='gray')\n",
    "            plt.title('Output')\n",
    "            plt.axis('off')\n",
    "        plt.suptitle('%d / %d - loss: %f' % (epoch+1, epochs, avg_loss))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13eacc96-819d-47d7-82d3-d453d5ec19fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bce_loss(y_real, y_pred, clip = False):\n",
    "    loss = nn.BCELoss()\n",
    "    #pos_weight = torch.ones([size])\n",
    "    #loss = nn.BCEWithLogitsLoss(pos_weight)\n",
    "    return loss((y_pred), y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd7bac3e-e828-4e7b-bbcb-f9881baebd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    model.eval()  # testing mode\n",
    "    Y_pred = [F.sigmoid(model(X_batch.to(device))) for X_batch, _ in data]\n",
    "    return np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f32a6-f347-4793-826c-9b52391cd0f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18fb300-a4e5-46a0-b9c2-d6ecb83e7c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convolutional = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 128 -> 64\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 64 -> 32\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        \n",
    "        )\n",
    "        \n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128*128), # output with 128x128 dimensions. \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutional(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fully_connected(x)\n",
    "        x = x.view(x.size(0), 1, 128, 128)  # Reshape output to match target size\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e72972a-850f-4bf6-b634-84f06753695d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 128, 128]             448\n",
      "              ReLU-2         [-1, 16, 128, 128]               0\n",
      "         MaxPool2d-3           [-1, 16, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]           4,640\n",
      "              ReLU-5           [-1, 32, 64, 64]               0\n",
      "         MaxPool2d-6           [-1, 32, 32, 32]               0\n",
      "            Conv2d-7           [-1, 64, 32, 32]          18,496\n",
      "              ReLU-8           [-1, 64, 32, 32]               0\n",
      "            Linear-9                  [-1, 128]       8,388,736\n",
      "             ReLU-10                  [-1, 128]               0\n",
      "           Linear-11                [-1, 16384]       2,113,536\n",
      "================================================================\n",
      "Total params: 10,525,856\n",
      "Trainable params: 10,525,856\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 7.88\n",
      "Params size (MB): 40.15\n",
      "Estimated Total Size (MB): 48.22\n",
      "----------------------------------------------------------------\n",
      "* Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [119,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [39,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m SimpleCNN()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m summary(model, (\u001b[39m3\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m train(model, optim\u001b[39m.\u001b[39;49mAdam(model\u001b[39m.\u001b[39;49mparameters()), bce_loss, \u001b[39m50\u001b[39;49m, train_loader, test_loader)\n",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, opt, loss_fn, epochs, train_loader, test_loader)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m# loss = loss_fn(Y_batch, torch.argmax(Y_pred, dim = 1))  # forward-pass\u001b[39;00m\n\u001b[1;32m     20\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(Y_batch, Y_pred)  \u001b[39m# forward-pass\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()  \u001b[39m# backward-pass\u001b[39;00m\n\u001b[1;32m     22\u001b[0m opt\u001b[39m.\u001b[39mstep()  \u001b[39m# update weights\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# calculate metrics to show the user\u001b[39;00m\n",
      "File \u001b[0;32m/work3/s183920/02514-DLCI/DLCI-venv/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/work3/s183920/02514-DLCI/DLCI-venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# Leasion | Not leasion data\n",
    "model = SimpleCNN().to(device)\n",
    "summary(model, (3, 128, 128))\n",
    "train(model, optim.Adam(model.parameters()), bce_loss, 50, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c97f2-3efc-41e1-b5a7-65aabb98af91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convolutional = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 128 -> 64\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 64 -> 32\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 32 -> 16\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        )\n",
    "        \n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(128*16*16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128*128), # output with 128x128 dimensions. \n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutional(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fully_connected(x)\n",
    "        x = x.view(x.size(0), 1, 128, 128)  # Reshape output to match target size\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5325f-ae15-43dc-81fb-5cd5e6f288e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Leasion | Not leasion data\n",
    "model = SimpleCNN2().to(device)\n",
    "summary(model, (3, 128, 128))\n",
    "train(model, optim.Adam(model.parameters()), bce_loss, 50, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ffd47e-66a3-4730-b6db-1d09792034ed",
   "metadata": {},
   "source": [
    "# With sigmoid binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7c5d365-7cf7-4d70-99a5-1291c5170926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convolutional = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 128 -> 64\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 64 -> 32\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        \n",
    "        )\n",
    "        \n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128*128), # output with 128x128 dimensions.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutional(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fully_connected(x)\n",
    "        x = x.view(x.size(0), 1, 128,128)  # Reshape output to match target sizez\n",
    "        x = torch.sigmoid(x) # Apply element wise sigmoid\n",
    "        x = (x > 0.5).float()  # Thresholding with a given threshold\n",
    "        \n",
    "         # Enable gradient calculation for the thresholded tensor\n",
    "        x.requires_grad_()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed2ed9-07dd-4050-aebe-b8d8df31076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 128, 128]             448\n",
      "              ReLU-2         [-1, 16, 128, 128]               0\n",
      "         MaxPool2d-3           [-1, 16, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]           4,640\n",
      "              ReLU-5           [-1, 32, 64, 64]               0\n",
      "         MaxPool2d-6           [-1, 32, 32, 32]               0\n",
      "            Conv2d-7           [-1, 64, 32, 32]          18,496\n",
      "              ReLU-8           [-1, 64, 32, 32]               0\n",
      "            Linear-9                  [-1, 128]       8,388,736\n",
      "             ReLU-10                  [-1, 128]               0\n",
      "           Linear-11                [-1, 16384]       2,113,536\n",
      "================================================================\n",
      "Total params: 10,525,856\n",
      "Trainable params: 10,525,856\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 7.88\n",
      "Params size (MB): 40.15\n",
      "Estimated Total Size (MB): 48.22\n",
      "----------------------------------------------------------------\n",
      "* Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "# Leasion | Not leasion data\n",
    "model = SimpleCNNB().to(device)\n",
    "summary(model, (3, 128, 128))\n",
    "train(model, optim.Adam(model.parameters()), bce_loss, 50, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0642b-25b0-4a01-8443-58d0f4d4682e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN2B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convolutional = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 128 -> 64\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 64 -> 32\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), # 32 -> 16\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        )\n",
    "        \n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(128*16*16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128*128), # output with 128x128 dimensions. \n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutional(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fully_connected(x)\n",
    "        x = x.view(x.size(0), 1, 128, 128)  # Reshape output to match target size\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7cdde-cff0-45d4-b346-95b36d6e29f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Leasion | Not leasion data\n",
    "model = SimpleCNN2B().to(device)\n",
    "summary(model, (3, 128, 128))\n",
    "train(model, optim.Adam(model.parameters()), bce_loss, 50, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e2e79-d846-4c03-bd82-b811be7ba24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31f1a6-d065-4b87-9d55-84b9b0663ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44187884-fd92-4b43-a131-5da2f2cf549f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a4065-385f-4c19-aabb-b31efd768e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@deathbeds/jupyterlab-fonts": {
   "styles": {
    ":root": {
     "--jp-code-font-size": "15px",
     "--jp-content-font-size1": "15px"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
